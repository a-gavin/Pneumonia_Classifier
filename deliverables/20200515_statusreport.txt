20200515_statusreport.txt

Having put in the initial leg work researching tools and methods last week, this week has been an opportunity for the group to both make use of said tools as well as reflect on how we can use these tools to achieve our goal.
This week, Alex used the PyTorch ImageFolder dataset to initialize a dataloader for use in training. Initially, Alex made use of his group’s submitted CNN for lab four. This allowed him to adjust hyperparameters to see how well a no-frills CNN could classify unaugmented data. He then followed this up by using a widely available PyTorch implementation of AlexNet to evaluate the performance of this architecture on the same problem, demonstrating the ease of retooling this dataloader in other architectures. In doing so, the question of what metric best suits our end goal came up in group discussions. Seeing that the dataset our group is using contains an unbalanced proportion of normal, viral, and bacterial pneumonia data, a simple evaluation of output prediction accuracy may be unsuitable. This is something the group aims to explore in the coming week.
Ivan and Chris continue down the data augmentation path, further exploring which data translations will provide the most noticeable boost in performance. In particular, it seems that geometric transformations, i.e. horizontal translations, rotations and cropping, provide the greatest boost in accuracy, followed closely by photometric augmentations like brightness and contrast. This gives a better idea of how our data should first be augmented to produce the most meaningful results compared to our baseline. Ivan and Chris are currently working on selectively implementing the data augmentations based on the performance boost cited in recent papers that have discussed this topic in detail.
Raleigh has altered the baseline architecture to better fit our classification task. This updated baseline bears resemblance to the AlexNet architecture. Additionally, Alex’s contributions for including the PyTorch ImageFolder as well as image resizing has been incorporated into the data loading for the baseline. In order to evaluate our model’s performance in a way that provides the best representation of its ability to perform such classifications on an unbalanced dataset new metrics were necessary. Calculations for precision, recall, and f1 scores have been added. Upon training completion, the state of the model is saved such that it can be restored for any future testing. Raleigh has run a small set of sample data through the baseline to ensure functionality of these new additions. From this point, the baseline is to be finalized such that we can train on unaugmented data in the coming week. Furthermore, modules for visual representations of model performance (e.g. confusion matrices) are to be added.
Matthew created a baseline implementation for the ResNet models provided in torchvision.models. This implementation allows for the configuration of any of the ResNet models through command line arguments. This new baseline for ResNet was built on top of the general baseline that Raleigh has been working on. Following this baseline of ResNet, we will be fully implementing ResNet instead of using the models provided in torchvision. This will allow us to modify the architecture as we see fit in order to improve our model.
