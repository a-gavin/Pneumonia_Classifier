20200508_statusreport.txt

Starting a project is always the hardest part. As of writing this, our several gigabyte dataset is on the cluster ready for us to classify. 
Ivan and Alex took one of the first steps in that process in preprocessing the dataset. They have spent time using PyTorch and PIL libraries to load, manipulate, and save data. Among other things, they have been able to rotate, mirror, increase brightness, and increase contrast in the x-ray images. Some additional image transformations they identified to explore further include translations as well as adding noise to images, although the latter they have identified as not supported by torchvision. 
In their search for image transformations, Ivan and Alex have identified the torchvision ImageFolder data loader which will greatly simplify the loading and manipulation of data. In their attempt to explore this, they were halted by shared directory permission issues which have been submitted as a private Piazza post for further clarification. Once this issue is cleared up, they aim to fully use the ImageFolder data loader to facilitate the training of a baseline model on our dataset.
Matthew and Raleigh are in charge of setting up a baseline architecture to compare its results against future, improved models. By taking a paired-programming approach, the two arrived at a strong foundation for such a baseline. At this stage, they have a simple CNN set up which has a small number of convolutional layers, a single max-pooling layer, and two fully-connected linear layers. The model is currently shown to produce high accuracies on an outside, labeled dataset. Going forward they will alter this architecture to be capable of learning on images of varying size such as to meet the requirements for our chest x-ray dataset. Certain hardcoded aspects of our current implementation will also be altered to provide greater flexibility in training.
Chris was and is currently in charge of more literature review, specifically for finding literature that references data augmentation and its implications for artificially enhancing the dataset. A few papers specifically state that data augmentation can have a performance increase of around ~3% on state of the art models. So we know our original plan of data augmentation will benefit our model, if done appropriately. How much benefit we can get remains yet to be seen. Furthermore, parallel research has been conducted on improving the efficiency of the sliding window problem. That is, as the image resolution goes up, the number of windows to parse the kernel over increases on the order of magnitudes. Solutions to this can be approached by incorporating region proposal layers that give a better representation of where an object might be amongst the large number of windows, rather than brute forcing every single window.
